# -*- coding: utf-8 -*-
"""Submission 1 : NLP - Movie Genre Data

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VL11JCL3b-CAyGyKiJ56RPPhlEYLWFki

Ahyar


 Bergabung sejak 03 Jun 2020

 Kota Bandung, Jawa Barat
"""

import pandas as pd
df = pd.read_csv('/kaggle_movie_train.csv')

df.info()

df.head()

df['genre'].unique()

df['genre'].value_counts()

# menghapus 4 genre
df = df[~df['genre'].isin(['drama','comedy','other','adventure','horror'])]
df['genre'].value_counts()

# mempertahankan kolom yang penting
df=df[["text","genre"]]
df.head()

#  one-hot-encoding dan membuat dataframe baru
category = pd.get_dummies(df.genre)
df_baru = pd.concat([df, category], axis=1)
df_baru = df_baru.drop(columns='genre')
df_baru

# mengubah nilai-nilai dari dataframe ke dalam tipe data numpy array 
text = df_baru['text'].values
label = df_baru[['action', 'romance', 'sci-fi', 'thriller']].values

# membagi data untuk training dan data untuk testing
from sklearn.model_selection import train_test_split
tweet_latih, tweet_test, label_latih, label_test = train_test_split(tweet, label, shuffle=True, test_size=0.2)

# mengubah setiap kata ke dalam bilangan numerik dan konversi menjadi sequence
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
 
tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(tweet_latih) 
tokenizer.fit_on_texts(tweet_test)
 
sekuens_latih = tokenizer.texts_to_sequences(tweet_latih)
sekuens_test = tokenizer.texts_to_sequences(tweet_test)
 
padded_latih = pad_sequences(sekuens_latih) 
padded_test = pad_sequences(sekuens_test)

# membuat layer embedding
import tensorflow as tf
from keras import regularizers
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(4, activation='softmax')
])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

#fungsi call back

class myCallback(tf.keras.callbacks.Callback):

  def on_epoch_end(self, epoch, logs={}):

    if(logs.get('accuracy') > 0.97 and logs.get('val_accuracy') > 0.92 ): 

      print("\nAkurasi telah mencapai >90%!")

      self.model.stop_training = True

callbacks = myCallback()

# melatih model
num_epochs = 30
history = model.fit(padded_latih, label_latih, batch_size=64, epochs=num_epochs, 
                    validation_data=(padded_test, label_test), verbose=2, 
                    callbacks=[callbacks])

# membuat model loss
import seaborn as sns
import matplotlib.pyplot as plt

plt.plot(history.history['loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train'], loc='upper right')
plt.show()

# membuat model accuracy
plt.plot(history.history['accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train'], loc='lower right')
plt.show()

# membuat plot training vs validasi accuracy

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'bo', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()
plt.figure()

plt.plot(epochs, loss, 'bo', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()